{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузим простой датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()\n",
    "observations = scale(dataset.data)\n",
    "tg = scale(dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(observations, tg, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "(379, 13) (379,)\n",
      "Test data:\n",
      "(127, 13) (127,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data:\")\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(\"Test data:\")\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сделаем все нужные нам блоки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorFunctionSTD():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Инициализация метода функции ошибки.\n",
    "        В функции ошибки нету параметров.\n",
    "        \"\"\"\n",
    "        self.params = []\n",
    "        self.grad_params = [np.zeros_like(self.params)]\n",
    "        pass\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"\n",
    "        Функция которая обнуляет градиенты\n",
    "        \"\"\"\n",
    "        self.grad_params = [np.zeros_like(self.params)]\n",
    "        pass\n",
    "    \n",
    "    def forward(self, predict, target):\n",
    "        \"\"\"\n",
    "        predict --- ответы предсказаные, вектор размера [batch_size x size]\n",
    "        target --- истиные ответы, вектор размера  [batch_size x size]\n",
    "        Считает среднее отклонение от истинного\n",
    "        \"\"\"\n",
    "        return (((predict - target).T@(predict - target))/predict.shape[0]).sum()\n",
    "    \n",
    "    def backward(self, predict, target):\n",
    "        \"\"\"\n",
    "        predict --- ответы предсказаные, вектор размера [batch_size x size]\n",
    "        target --- истиные ответы, вектор размера  [batch_size x size]\n",
    "        Возврщает производную ошибки по предсказаным ответам\n",
    "        \"\"\"\n",
    "        return 2*(predict - target)/predict.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        \"\"\"\n",
    "        input_size --- размер входа даного слоя\n",
    "        output_size --- размер выхода даного слоя\n",
    "        \"\"\"\n",
    "        self.weights = np.random.randn(input_size, output_size)*0.01\n",
    "        self.biases = np.zeros(output_size)\n",
    "        self.params = [self.weights, self.biases]\n",
    "        self.grad_params = [np.zeros_like(self.weights), np.zeros_like(self.biases)]\n",
    "        pass\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"\n",
    "        Функция которая обнуляет градиенты\n",
    "        \"\"\"\n",
    "        self.grad_params = [np.zeros_like(self.weights), np.zeros_like(self.biases)]\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        На вход нам дается выход предыдущего слоя нейронной сети\n",
    "        На выходе должны получить вектор ответов текущего слоя\n",
    "        На вход подается вектор размера [batch_size x input_size]\n",
    "        На выходе должен быть вектор размера [batch_size x output_size]\n",
    "        \"\"\"\n",
    "        self.__input = np.array(input)\n",
    "        self.__output = self.__input@self.weights\n",
    "        self.__output = self.__output + np.reshape(self.biases, [1, -1])\n",
    "        return self.__output\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        На вход подаются градиента ВЫХОДУ текущего слоя\n",
    "        На выход нужно дать градиенты по ВХОДУ текущего слоя и по параметрам текущего слоя\n",
    "        На вход подается вектор размера [batch_size x output_size]\n",
    "        На выходе должен быть вектор размера [batch_size x intput_size] --- градиент по ВХОДУ\n",
    "        \n",
    "        (Также после выполенния данного метода сохраняются градиенты по параметрам модели)\n",
    "        \"\"\"\n",
    "        grad_weight = self.__input.T@grad_output\n",
    "        grad_biases = grad_output.sum(axis = 0)\n",
    "        \n",
    "        grad_input = grad_output@self.weights.T\n",
    "        \n",
    "        # np.ravel() --- вытаскивает матриицу в вектор (аналог np.reshape(arr ,[-1]))\n",
    "        # np.r_[arr1, arr2] --- конкатенирует два вектора\n",
    "        self.grad_params = [grad_weight, grad_biases]\n",
    "        return grad_input\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLu:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Инициализация нелинейной функции ReLu.\n",
    "        В функции ReLu нету параметров.\n",
    "        \"\"\"\n",
    "        self.params = []\n",
    "        self.grad_params = [np.zeros_like(self.params)]\n",
    "        pass\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"\n",
    "        Функция которая обнуляет градиенты\n",
    "        \"\"\"\n",
    "        self.grad_params = [np.zeros_like(self.params)]\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        На вход нам дается выход предыдущего слоя нейронной сети\n",
    "        На выходе должны получить вектор ответов текущего слоя\n",
    "        На вход подается вектор размера [batch_size x input_size]\n",
    "        На выходе должен быть вектор размера [batch_size x input_size]\n",
    "        \"\"\"\n",
    "        self.__input = np.array(input)\n",
    "        self.__output = np.abs(input*(1.0 + np.sign(input))/2.0)\n",
    "        return self.__output\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        На вход подаются градиента ВЫХОДУ текущего слоя\n",
    "        На выход нужно дать градиенты по ВХОДУ текущего слоя и по параметрам текущего слоя\n",
    "        На вход подается вектор размера [batch_size x intput_size]\n",
    "        На выходе должен быть вектор размера [batch_size x intput_size] --- градиент по ВХОДУ\n",
    "        \n",
    "        (Также после выполенния данного метода сохраняются градиенты по параметрам модели)\n",
    "        \"\"\"        \n",
    "        grad_input = np.multiply(grad_output, np.sign(self.__output))\n",
    "        return grad_input\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Здесь еще нужно добавить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dropout():\n",
    "    def __init__(self, p = 0.5):\n",
    "        pass\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input):\n",
    "        pass\n",
    "    \n",
    "    def backward():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теперь нам нужен оптимизатор параметров:\n",
    "\n",
    "Будем использовать стандартный градиентный спуск (для начала напишем свой).\n",
    "\n",
    "Это просто функция которая делает один шаг градиентного спуска имея градиенты всех параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GD:\n",
    "    def __init__(self, parameters = None, alpha = 0.01):\n",
    "        \"\"\"\n",
    "        parameters это вектор размера [size],\n",
    "        alpha это шаг градиентного спуска\n",
    "        \"\"\"\n",
    "\n",
    "        self.__parameters = parameters\n",
    "        self.__alpha = alpha\n",
    "        pass\n",
    "    \n",
    "    def set_parameters(self, parameters):\n",
    "        \"\"\"\n",
    "        Функция которая устанавливает вектор параметров\n",
    "        parameters --- вектор размера [size]\n",
    "        \"\"\"\n",
    "        self.__parameters = parameters\n",
    "        pass\n",
    "    \n",
    "    def step(self, gradients):\n",
    "        \"\"\"\n",
    "        gradients это вектор градиентов по параметрам модели размеры [size]\n",
    "        \n",
    "        Функция обновляет вектор параметров self.__parameters\n",
    "        \"\"\"\n",
    "        if self.__parameters is None:\n",
    "            self.__parameters = np.zeros_like(gradients)\n",
    "        self.__parameters = self.__parameters - self.__alpha*gradients\n",
    "        pass\n",
    "    \n",
    "    def parameters(self):\n",
    "        \"\"\"\n",
    "        Функция возвращает вектор параметров\n",
    "        \"\"\"\n",
    "        return self.__parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теперь строем всю полносвязную сеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "    def __init__(self, input_size, error_function = ErrorFunctionSTD(), optimizer = GD()):\n",
    "        \"\"\"\n",
    "        Иницилизирует полносвязную нейронную сеть\n",
    "        input_size это число которое указывает на количество входов нейросети\n",
    "        error_function это функция ошибки, которую мы оптимизируем\n",
    "        optimizer это метод оптимизации нейросети\n",
    "        \"\"\"\n",
    "        self.__error_function = error_function\n",
    "        self.__optimizer = optimizer\n",
    "        \n",
    "# здесь задается сама структуреа нейросети\n",
    "        self.__list_of_layer = []\n",
    "        self.__list_of_layer.append(Dense(input_size, 9))\n",
    "        self.__list_of_layer.append(ReLu())\n",
    "        self.__list_of_layer.append(Dense(9, 5))\n",
    "        self.__list_of_layer.append(ReLu())\n",
    "        self.__list_of_layer.append(Dense(5, 1))\n",
    "        \n",
    "# здесь мы инициализируем нейросеть\n",
    "        self.__init_weight()\n",
    "\n",
    "    def __get_weights(self):\n",
    "        \"\"\"\n",
    "        Функция которая возврвщает вектор параметров нейросети в виде вектора\n",
    "        \"\"\"\n",
    "        weights = []\n",
    "        for layer in self.__list_of_layer:\n",
    "            for param in layer.params:\n",
    "                weights += param.ravel().tolist()\n",
    "        return np.array(weights)\n",
    "\n",
    "    def __set_weights(self, weights):\n",
    "        \"\"\"\n",
    "        Функция которая по заданому вектору задает все параметры нейросети\n",
    "        \"\"\"\n",
    "        i = 0\n",
    "        for layer in self.__list_of_layer:\n",
    "            for param in layer.params:\n",
    "                l = param.size\n",
    "                param[:] = weights[i:i+l].reshape(param.shape)\n",
    "                i += l\n",
    "\n",
    "    def __init_weight(self):\n",
    "        \"\"\"\n",
    "        Функция которая инициализирует веса нейросети\n",
    "        \"\"\"\n",
    "        i = 0\n",
    "        for layer in self.__list_of_layer:\n",
    "            for param in layer.params:\n",
    "                l = param.size\n",
    "                param[:] = np.random.randn(l).reshape(param.shape)*0.01\n",
    "                i += l\n",
    "                \n",
    "    def __get_gradients(self):\n",
    "        \"\"\"\n",
    "        Функция которая возврвщает вектор градиентов параметров нейросети в виде вектора\n",
    "        \"\"\"\n",
    "        gradients = []\n",
    "        for layer in self.__list_of_layer:\n",
    "            for grad_param in layer.grad_params:\n",
    "                gradients += grad_param.ravel().tolist()\n",
    "        return np.array(gradients)\n",
    "    \n",
    "    def __forward(self, input):\n",
    "        \"\"\"\n",
    "        Функция которая делает проход вперед по нейросети\n",
    "        \"\"\"\n",
    "        output = input\n",
    "        for layer in self.__list_of_layer:\n",
    "            output = layer.forward(output)\n",
    "        return output\n",
    "    \n",
    "    def __backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Функция которая делает проход назад по нейросети\n",
    "        \"\"\"\n",
    "        grad = grad_output\n",
    "        for layer in list(reversed(self.__list_of_layer)):\n",
    "            grad = layer.backward(grad)\n",
    "        pass\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"\n",
    "        Функция которая обнуляет градиенты всех параметров в нейросети\n",
    "        \"\"\"\n",
    "        for layer in self.__list_of_layer:\n",
    "            layer.zero_grad()\n",
    "        pass\n",
    "    \n",
    "    def predict(self, input):\n",
    "        \"\"\"\n",
    "        Функция которая делает предсказание по данным\n",
    "        \"\"\"\n",
    "        output = input\n",
    "        for layer in self.__list_of_layer:\n",
    "            output = layer.forward(output)\n",
    "        return output\n",
    "    \n",
    "    def fit(self, X = None, y = None, epochs = 100):\n",
    "        \"\"\"\n",
    "        Функция которая обучает нейросеть\n",
    "        X это матрица входов размера [batch_size x input_size]\n",
    "        y это вектор входов размера [batch_size x output_size]\n",
    "        epochs это число указывающее количество эпох в обучении\n",
    "        \"\"\"\n",
    "        if X is None:\n",
    "            return \n",
    "        if y is None:\n",
    "            return\n",
    "\n",
    "        weights = self.__get_weights()\n",
    "        self.__optimizer.set_parameters(weights)\n",
    "        \n",
    "        for epoch in tqdm(range(epochs)):\n",
    "# Обнуляем градиенты, чтобы старые нам не помешали\n",
    "            self.zero_grad()\n",
    "    \n",
    "# Считаем градиент ошибки по выходу нейросети\n",
    "            grad_output = self.__error_function.backward(self.__forward(X), y)\n",
    "        \n",
    "# Считаем градиент ошибки по всем параметрам нейросети\n",
    "            self.__backward(grad_output)\n",
    "            \n",
    "# Вытаскиваем эти градиенты\n",
    "            gradients = self.__get_gradients()\n",
    "        \n",
    "# Делаем шаг оптимизации параметров\n",
    "            self.__optimizer.step(gradients)\n",
    "            \n",
    "# Обновляем веса нейросети\n",
    "            self.__set_weights(self.__optimizer.parameters())\n",
    "    \n",
    "        return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_function = ErrorFunctionSTD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network(input_size = 13, error_function=error_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка на train: 0.8847349214233711\n"
     ]
    }
   ],
   "source": [
    "print(\"Ошибка на train:\", error_function.forward(network.predict(X_train), y_train.reshape([-1,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [00:10<00:00, 3649.48it/s]\n"
     ]
    }
   ],
   "source": [
    "network.fit(X_train, y_train.reshape([-1,1]), epochs=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка на train: 0.04387810843026418\n"
     ]
    }
   ],
   "source": [
    "print(\"Ошибка на train:\", error_function.forward(network.predict(X_train), y_train.reshape([-1,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка на test: 0.10640393088032178\n"
     ]
    }
   ],
   "source": [
    "print(\"Ошибка на test:\", error_function.forward(network.predict(X_test), y_test.reshape([-1,1])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
